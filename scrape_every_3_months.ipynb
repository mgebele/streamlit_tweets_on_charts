{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Scrape all tweets every 3 months!\n",
    "# 2. Store in csvs locally\n",
    "# 3. push csvs automatically into repo here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.graph_objects as go\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from dateutil import tz\n",
    "import glob\n",
    "import quandl as q\n",
    "import re\n",
    "import streamlit as st\n",
    "st.set_page_config(layout=\"wide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API credentials\n",
    "consumer_key = os.environ[\"twtr_consumer_key\"]\n",
    "consumer_secret = os.environ[\"twtr_consumer_secret\"]\n",
    "access_key = os.environ[\"twtr_access_key\"]\n",
    "access_secret = os.environ[\"twtr_access_secret\"]\n",
    "quandl_api_key = os.environ[\"quandl_api_key\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inmortalcrypto',\n",
       " 'cz_binance',\n",
       " 'AltcoinGordon',\n",
       " '100trillionUSD',\n",
       " 'CryptoHayes',\n",
       " 'Ninjascalp',\n",
       " 'APompliano',\n",
       " 'DrGreenApe',\n",
       " 'saylor',\n",
       " 'Grayscale',\n",
       " 'ForbesCrypto',\n",
       " 'crypto_birb',\n",
       " 'BitcoinMagazine',\n",
       " 'IamNomad',\n",
       " 'BarrySilbert',\n",
       " 'siliconebunker',\n",
       " 'woonomic',\n",
       " 'TheCryptoDog',\n",
       " 'BillyBobBaghold',\n",
       " 'RaoulGMI',\n",
       " 'depression2019',\n",
       " 'BTCTN',\n",
       " 'cryptocobain',\n",
       " 'ThinkingUSD',\n",
       " 'LynAldenContact',\n",
       " 'whale_alert',\n",
       " 'coinmamba',\n",
       " 'krakenfx',\n",
       " 'Cointelegraph',\n",
       " 'Alice_comfy',\n",
       " 'VitalikButerin',\n",
       " 'crypto_color_',\n",
       " 'scottmelker',\n",
       " 'wmd4x']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_stored_twitter_user_csvs():\n",
    "    # get all csv file names - already scraped users\n",
    "    extension = 'csv'\n",
    "    all_twitter_user_scraped_csvs = glob.glob(\n",
    "        r'twitterdata/*.{}'.format(extension))  # CHANGE FOR SHARE STREAMLIT to /\n",
    "    # filter the price csv\n",
    "    all_twitter_user_scraped_csvs = [\n",
    "        k for k in all_twitter_user_scraped_csvs if 'BITFINEX' not in k]\n",
    "    # filter the price csv\n",
    "    all_twitter_user_scraped_csvs = [\n",
    "        k for k in all_twitter_user_scraped_csvs if 'relevant_words' not in k]\n",
    "    display_name_all_twitter_user_scraped_csvs = [\n",
    "        i.split(' ', 1)[0].split(\"twitterdata\\\\\")[1] for i in all_twitter_user_scraped_csvs]\n",
    "\n",
    "    return display_name_all_twitter_user_scraped_csvs, all_twitter_user_scraped_csvs\n",
    "\n",
    "display_name_all_twitter_user_scraped_csvs, all_twitter_user_scraped_csvs = get_all_stored_twitter_user_csvs()\n",
    "unique_display_name_all_twitter_user_scraped_csvs = list(set(display_name_all_twitter_user_scraped_csvs))\n",
    "unique_display_name_all_twitter_user_scraped_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KanavKariya\n",
      "punk6529\n",
      "thedefiedge\n",
      "AviFelman\n",
      "hosseeb\n",
      "gametheorizing\n",
      "HsakaTrades\n",
      "AriDavidPaul\n",
      "iamDCinvestor\n",
      "lightcrypto\n",
      "CryptoKaleo\n",
      "Arthur_0x\n",
      "santiagoroel\n",
      "AlamedaTrabucco\n",
      "john_j_brown\n",
      "hasufl\n",
      "AngeloBTC\n",
      "ErikVoorhees\n"
     ]
    }
   ],
   "source": [
    "for screen_name in unique_display_name_all_twitter_user_scraped_csvs:\n",
    "    print(screen_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KanavKariya\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...822 tweets downloaded so far\n",
      "...822 tweets downloaded so far\n",
      "punk6529\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1798 tweets downloaded so far\n",
      "...1998 tweets downloaded so far\n",
      "...2198 tweets downloaded so far\n",
      "...2398 tweets downloaded so far\n",
      "...2597 tweets downloaded so far\n",
      "...2797 tweets downloaded so far\n",
      "...2997 tweets downloaded so far\n",
      "...3197 tweets downloaded so far\n",
      "...3236 tweets downloaded so far\n",
      "...3236 tweets downloaded so far\n",
      "thedefiedge\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...2000 tweets downloaded so far\n",
      "...2200 tweets downloaded so far\n",
      "...2400 tweets downloaded so far\n",
      "...2538 tweets downloaded so far\n",
      "...2538 tweets downloaded so far\n",
      "AviFelman\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1199 tweets downloaded so far\n",
      "...1399 tweets downloaded so far\n",
      "...1598 tweets downloaded so far\n",
      "...1798 tweets downloaded so far\n",
      "...1998 tweets downloaded so far\n",
      "...2198 tweets downloaded so far\n",
      "...2398 tweets downloaded so far\n",
      "...2598 tweets downloaded so far\n",
      "...2798 tweets downloaded so far\n",
      "...2998 tweets downloaded so far\n",
      "...3197 tweets downloaded so far\n",
      "...3245 tweets downloaded so far\n",
      "...3245 tweets downloaded so far\n",
      "hosseeb\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...796 tweets downloaded so far\n",
      "...996 tweets downloaded so far\n",
      "...1195 tweets downloaded so far\n",
      "...1394 tweets downloaded so far\n",
      "...1594 tweets downloaded so far\n",
      "...1794 tweets downloaded so far\n",
      "...1993 tweets downloaded so far\n",
      "...2193 tweets downloaded so far\n",
      "...2392 tweets downloaded so far\n",
      "...2590 tweets downloaded so far\n",
      "...2788 tweets downloaded so far\n",
      "...2985 tweets downloaded so far\n",
      "...3181 tweets downloaded so far\n",
      "...3181 tweets downloaded so far\n",
      "gametheorizing\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1751 tweets downloaded so far\n",
      "...1751 tweets downloaded so far\n",
      "HsakaTrades\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1199 tweets downloaded so far\n",
      "...1398 tweets downloaded so far\n",
      "...1598 tweets downloaded so far\n",
      "...1798 tweets downloaded so far\n",
      "...1998 tweets downloaded so far\n",
      "...2198 tweets downloaded so far\n",
      "...2398 tweets downloaded so far\n",
      "...2598 tweets downloaded so far\n",
      "...2798 tweets downloaded so far\n",
      "...2998 tweets downloaded so far\n",
      "...3197 tweets downloaded so far\n",
      "...3247 tweets downloaded so far\n",
      "...3247 tweets downloaded so far\n",
      "AriDavidPaul\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...2000 tweets downloaded so far\n",
      "...2200 tweets downloaded so far\n",
      "...2400 tweets downloaded so far\n",
      "...2600 tweets downloaded so far\n",
      "...2800 tweets downloaded so far\n",
      "...3000 tweets downloaded so far\n",
      "...3200 tweets downloaded so far\n",
      "...3248 tweets downloaded so far\n",
      "...3248 tweets downloaded so far\n",
      "iamDCinvestor\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...2000 tweets downloaded so far\n",
      "...2200 tweets downloaded so far\n",
      "...2400 tweets downloaded so far\n",
      "...2600 tweets downloaded so far\n",
      "...2800 tweets downloaded so far\n",
      "...3000 tweets downloaded so far\n",
      "...3200 tweets downloaded so far\n",
      "...3250 tweets downloaded so far\n",
      "...3250 tweets downloaded so far\n",
      "lightcrypto\n",
      "...398 tweets downloaded so far\n",
      "...597 tweets downloaded so far\n",
      "...795 tweets downloaded so far\n",
      "...995 tweets downloaded so far\n",
      "...1194 tweets downloaded so far\n",
      "...1394 tweets downloaded so far\n",
      "...1593 tweets downloaded so far\n",
      "...1793 tweets downloaded so far\n",
      "...1993 tweets downloaded so far\n",
      "...2192 tweets downloaded so far\n",
      "...2391 tweets downloaded so far\n",
      "...2591 tweets downloaded so far\n",
      "...2790 tweets downloaded so far\n",
      "...2990 tweets downloaded so far\n",
      "...3190 tweets downloaded so far\n",
      "...3202 tweets downloaded so far\n",
      "...3202 tweets downloaded so far\n",
      "CryptoKaleo\n",
      "...375 tweets downloaded so far\n",
      "...575 tweets downloaded so far\n",
      "...775 tweets downloaded so far\n",
      "...975 tweets downloaded so far\n",
      "...1175 tweets downloaded so far\n",
      "...1375 tweets downloaded so far\n",
      "...1574 tweets downloaded so far\n",
      "...1774 tweets downloaded so far\n",
      "...1974 tweets downloaded so far\n",
      "...2174 tweets downloaded so far\n",
      "...2374 tweets downloaded so far\n",
      "...2574 tweets downloaded so far\n",
      "...2773 tweets downloaded so far\n",
      "...2973 tweets downloaded so far\n",
      "...3173 tweets downloaded so far\n",
      "...3219 tweets downloaded so far\n",
      "...3219 tweets downloaded so far\n",
      "Arthur_0x\n",
      "...400 tweets downloaded so far\n",
      "...598 tweets downloaded so far\n",
      "...798 tweets downloaded so far\n",
      "...997 tweets downloaded so far\n",
      "...1196 tweets downloaded so far\n",
      "...1393 tweets downloaded so far\n",
      "...1591 tweets downloaded so far\n",
      "...1788 tweets downloaded so far\n",
      "...1984 tweets downloaded so far\n",
      "...2184 tweets downloaded so far\n",
      "...2379 tweets downloaded so far\n",
      "...2578 tweets downloaded so far\n",
      "...2778 tweets downloaded so far\n",
      "...2976 tweets downloaded so far\n",
      "...3176 tweets downloaded so far\n",
      "...3184 tweets downloaded so far\n",
      "...3184 tweets downloaded so far\n",
      "santiagoroel\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...2000 tweets downloaded so far\n",
      "...2200 tweets downloaded so far\n",
      "...2400 tweets downloaded so far\n",
      "...2600 tweets downloaded so far\n",
      "...2800 tweets downloaded so far\n",
      "...3000 tweets downloaded so far\n",
      "...3199 tweets downloaded so far\n",
      "...3205 tweets downloaded so far\n",
      "...3205 tweets downloaded so far\n",
      "AlamedaTrabucco\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...2000 tweets downloaded so far\n",
      "...2200 tweets downloaded so far\n",
      "...2400 tweets downloaded so far\n",
      "...2600 tweets downloaded so far\n",
      "...2800 tweets downloaded so far\n",
      "...3000 tweets downloaded so far\n",
      "...3200 tweets downloaded so far\n",
      "...3246 tweets downloaded so far\n",
      "...3246 tweets downloaded so far\n",
      "john_j_brown\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...876 tweets downloaded so far\n",
      "...876 tweets downloaded so far\n",
      "hasufl\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...999 tweets downloaded so far\n",
      "...1199 tweets downloaded so far\n",
      "...1399 tweets downloaded so far\n",
      "...1599 tweets downloaded so far\n",
      "...1799 tweets downloaded so far\n",
      "...1999 tweets downloaded so far\n",
      "...2199 tweets downloaded so far\n",
      "...2399 tweets downloaded so far\n",
      "...2599 tweets downloaded so far\n",
      "...2799 tweets downloaded so far\n",
      "...2999 tweets downloaded so far\n",
      "...3199 tweets downloaded so far\n",
      "...3249 tweets downloaded so far\n",
      "...3249 tweets downloaded so far\n",
      "AngeloBTC\n",
      "...399 tweets downloaded so far\n",
      "...599 tweets downloaded so far\n",
      "...798 tweets downloaded so far\n",
      "...998 tweets downloaded so far\n",
      "...1197 tweets downloaded so far\n",
      "...1396 tweets downloaded so far\n",
      "...1592 tweets downloaded so far\n",
      "...1790 tweets downloaded so far\n",
      "...1988 tweets downloaded so far\n",
      "...2180 tweets downloaded so far\n",
      "...2373 tweets downloaded so far\n",
      "...2567 tweets downloaded so far\n",
      "...2765 tweets downloaded so far\n",
      "...2960 tweets downloaded so far\n",
      "...3129 tweets downloaded so far\n",
      "...3129 tweets downloaded so far\n",
      "ErikVoorhees\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...799 tweets downloaded so far\n",
      "...999 tweets downloaded so far\n",
      "...1199 tweets downloaded so far\n",
      "...1399 tweets downloaded so far\n",
      "...1599 tweets downloaded so far\n",
      "...1798 tweets downloaded so far\n",
      "...1998 tweets downloaded so far\n",
      "...2198 tweets downloaded so far\n",
      "...2398 tweets downloaded so far\n",
      "...2598 tweets downloaded so far\n",
      "...2798 tweets downloaded so far\n",
      "...2998 tweets downloaded so far\n",
      "...3198 tweets downloaded so far\n",
      "...3208 tweets downloaded so far\n",
      "...3208 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "for screen_name in unique_display_name_all_twitter_user_scraped_csvs:\n",
    "\n",
    "    try:\n",
    "        print(screen_name)\n",
    "        # Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "        # authorize twitter, initialize tweepy\n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_key, access_secret)\n",
    "        api = tweepy.API(auth)\n",
    "\n",
    "        # initialize a list to hold all the tweepy Tweets\n",
    "        alltweets = []\n",
    "\n",
    "        try:\n",
    "            # make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "            new_tweets = api.user_timeline(screen_name=screen_name, count=200)\n",
    "        except:\n",
    "            st.error('Username does not exist')\n",
    "\n",
    "        # save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "        # save the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "        my_bar = st.progress(0)\n",
    "        progress_complete = 0\n",
    "\n",
    "        # keep grabbing tweets until there are no tweets left to grab\n",
    "        while len(new_tweets) > 0:\n",
    "\n",
    "            progress_complete += 7\n",
    "            if progress_complete >= 100:\n",
    "                progress_complete = 100\n",
    "            my_bar.progress(progress_complete)\n",
    "\n",
    "            # all subsiquent requests use the max_id param to prevent duplicates\n",
    "            new_tweets = api.user_timeline(\n",
    "                screen_name=screen_name, count=200, max_id=oldest)\n",
    "\n",
    "            # save most recent tweets\n",
    "            alltweets.extend(new_tweets)\n",
    "\n",
    "            # update the id of the oldest tweet less one\n",
    "            oldest = alltweets[-1].id - 1\n",
    "\n",
    "            print(f\"...{len(alltweets)} tweets downloaded so far\")\n",
    "\n",
    "        # transform the tweepy tweets into a 2D array that will populate the csv\n",
    "        outtweets = [[tweet.id_str, tweet.created_at, tweet.text]\n",
    "                        for tweet in alltweets]\n",
    "\n",
    "        # remove progress bar now after completion\n",
    "        my_bar.empty()\n",
    "        with open(r'twitterdata/{0} {1}.csv'.format(screen_name, oldest), 'w',  encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"id\", \"created_at\", \"text\"])\n",
    "            writer.writerows(outtweets)\n",
    "    except:\n",
    "        print(\"error for {}\".format(screen_name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43f82cd4cb96a440704902f5d6ad1c0a1208589500b37b572d871d157e2519a1"
  },
  "kernelspec": {
   "display_name": "Python 2.7.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
