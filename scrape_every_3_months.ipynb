{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Scrape all tweets every 3 months!\n",
    "# 2. Store in csvs locally\n",
    "# 3. push csvs automatically into repo here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.graph_objects as go\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from dateutil import tz\n",
    "import glob\n",
    "import quandl as q\n",
    "import re\n",
    "import streamlit as st\n",
    "st.set_page_config(layout=\"wide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API credentials\n",
    "consumer_key = os.environ[\"twtr_consumer_key\"]\n",
    "consumer_secret = os.environ[\"twtr_consumer_secret\"]\n",
    "access_key = os.environ[\"twtr_access_key\"]\n",
    "access_secret = os.environ[\"twtr_access_secret\"]\n",
    "quandl_api_key = os.environ[\"quandl_api_key\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gametheorizing',\n",
       " 'john_j_brown',\n",
       " 'TheCryptoDog',\n",
       " 'scottmelker',\n",
       " 'AviFelman',\n",
       " 'ForbesCrypto',\n",
       " 'lightcrypto',\n",
       " 'CryptoHayes',\n",
       " 'punk6529',\n",
       " 'wmd4x',\n",
       " 'woonomic',\n",
       " 'AngeloBTC',\n",
       " 'coinmamba',\n",
       " 'KanavKariya',\n",
       " 'depression2019',\n",
       " 'hosseeb',\n",
       " 'BTCTN',\n",
       " 'VitalikButerin',\n",
       " 'whale_alert',\n",
       " 'Ninjascalp',\n",
       " 'HsakaTrades',\n",
       " 'RaoulGMI',\n",
       " 'cz_binance',\n",
       " 'ThinkingUSD',\n",
       " 'BarrySilbert',\n",
       " 'cryptocobain',\n",
       " 'crypto_birb',\n",
       " 'crypto_color_',\n",
       " 'iamDCinvestor',\n",
       " 'BitcoinMagazine',\n",
       " 'inmortalcrypto',\n",
       " 'Grayscale',\n",
       " 'LynAldenContact',\n",
       " 'Arthur_0x',\n",
       " 'IamNomad',\n",
       " 'Cointelegraph',\n",
       " 'hasufl',\n",
       " 'AriDavidPaul',\n",
       " 'BillyBobBaghold',\n",
       " 'saylor',\n",
       " 'Alice_comfy',\n",
       " 'santiagoroel',\n",
       " 'siliconebunker',\n",
       " 'CryptoKaleo',\n",
       " 'APompliano',\n",
       " 'ErikVoorhees',\n",
       " 'krakenfx',\n",
       " 'DrGreenApe',\n",
       " 'thedefiedge',\n",
       " 'AltcoinGordon',\n",
       " '100trillionUSD',\n",
       " 'AlamedaTrabucco']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_stored_twitter_user_csvs():\n",
    "    # get all csv file names - already scraped users\n",
    "    extension = 'csv'\n",
    "    all_twitter_user_scraped_csvs = glob.glob(\n",
    "        r'twitterdata/*.{}'.format(extension))  # CHANGE FOR SHARE STREAMLIT to /\n",
    "    # filter the price csv\n",
    "    all_twitter_user_scraped_csvs = [\n",
    "        k for k in all_twitter_user_scraped_csvs if 'BITFINEX' not in k]\n",
    "    # filter the price csv\n",
    "    all_twitter_user_scraped_csvs = [\n",
    "        k for k in all_twitter_user_scraped_csvs if 'relevant_words' not in k]\n",
    "    display_name_all_twitter_user_scraped_csvs = [\n",
    "        i.split(' ', 1)[0].split(\"twitterdata\\\\\")[1] for i in all_twitter_user_scraped_csvs]\n",
    "\n",
    "    return display_name_all_twitter_user_scraped_csvs, all_twitter_user_scraped_csvs\n",
    "\n",
    "display_name_all_twitter_user_scraped_csvs, all_twitter_user_scraped_csvs = get_all_stored_twitter_user_csvs()\n",
    "unique_display_name_all_twitter_user_scraped_csvs = list(set(display_name_all_twitter_user_scraped_csvs))\n",
    "unique_display_name_all_twitter_user_scraped_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_display_name_all_twitter_user_scraped_csvs = ['siliconebunker','Chubbicorn219','kamikaz_ETH','LifeNFT_','cryptoPothu','Cov_duk' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "siliconebunker\n",
      "Chubbicorn219\n",
      "kamikaz_ETH\n",
      "LifeNFT_\n",
      "cryptoPothu\n",
      "Cov_duk\n"
     ]
    }
   ],
   "source": [
    "for screen_name in unique_display_name_all_twitter_user_scraped_csvs:\n",
    "    print(screen_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "siliconebunker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 10:29:59.548 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\mg\\.conda\\envs\\btcpred\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...2000 tweets downloaded so far\n",
      "...2199 tweets downloaded so far\n",
      "...2396 tweets downloaded so far\n",
      "...2596 tweets downloaded so far\n",
      "...2796 tweets downloaded so far\n",
      "...2996 tweets downloaded so far\n",
      "...3195 tweets downloaded so far\n",
      "...3245 tweets downloaded so far\n",
      "...3245 tweets downloaded so far\n",
      "Chubbicorn219\n",
      "...400 tweets downloaded so far\n",
      "...599 tweets downloaded so far\n",
      "...799 tweets downloaded so far\n",
      "...999 tweets downloaded so far\n",
      "...1199 tweets downloaded so far\n",
      "...1399 tweets downloaded so far\n",
      "...1599 tweets downloaded so far\n",
      "...1798 tweets downloaded so far\n",
      "...1998 tweets downloaded so far\n",
      "...2198 tweets downloaded so far\n",
      "...2398 tweets downloaded so far\n",
      "...2598 tweets downloaded so far\n",
      "...2798 tweets downloaded so far\n",
      "...2998 tweets downloaded so far\n",
      "...3198 tweets downloaded so far\n",
      "...3242 tweets downloaded so far\n",
      "...3242 tweets downloaded so far\n",
      "kamikaz_ETH\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...1998 tweets downloaded so far\n",
      "...2187 tweets downloaded so far\n",
      "...2376 tweets downloaded so far\n",
      "...2566 tweets downloaded so far\n",
      "...2757 tweets downloaded so far\n",
      "...2847 tweets downloaded so far\n",
      "...2847 tweets downloaded so far\n",
      "LifeNFT_\n",
      "...63 tweets downloaded so far\n",
      "cryptoPothu\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1396 tweets downloaded so far\n",
      "...1396 tweets downloaded so far\n",
      "Cov_duk\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...2000 tweets downloaded so far\n",
      "...2200 tweets downloaded so far\n",
      "...2400 tweets downloaded so far\n",
      "...2582 tweets downloaded so far\n",
      "...2582 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "for screen_name in unique_display_name_all_twitter_user_scraped_csvs:\n",
    "\n",
    "    try:\n",
    "        print(screen_name)\n",
    "        # Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "        # authorize twitter, initialize tweepy\n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_key, access_secret)\n",
    "        api = tweepy.API(auth)\n",
    "\n",
    "        # initialize a list to hold all the tweepy Tweets\n",
    "        alltweets = []\n",
    "\n",
    "        try:\n",
    "            # make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "            new_tweets = api.user_timeline(screen_name=screen_name, count=200)\n",
    "        except:\n",
    "            st.error('Username does not exist')\n",
    "\n",
    "        # save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "        # save the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "        my_bar = st.progress(0)\n",
    "        progress_complete = 0\n",
    "\n",
    "        # keep grabbing tweets until there are no tweets left to grab\n",
    "        while len(new_tweets) > 0:\n",
    "\n",
    "            progress_complete += 7\n",
    "            if progress_complete >= 100:\n",
    "                progress_complete = 100\n",
    "            my_bar.progress(progress_complete)\n",
    "\n",
    "            # all subsiquent requests use the max_id param to prevent duplicates\n",
    "            new_tweets = api.user_timeline(\n",
    "                screen_name=screen_name, count=200, max_id=oldest)\n",
    "\n",
    "            # save most recent tweets\n",
    "            alltweets.extend(new_tweets)\n",
    "\n",
    "            # update the id of the oldest tweet less one\n",
    "            oldest = alltweets[-1].id - 1\n",
    "\n",
    "            print(f\"...{len(alltweets)} tweets downloaded so far\")\n",
    "\n",
    "        # transform the tweepy tweets into a 2D array that will populate the csv\n",
    "        outtweets = [[tweet.id_str, tweet.created_at, tweet.text]\n",
    "                        for tweet in alltweets]\n",
    "\n",
    "        # remove progress bar now after completion\n",
    "        my_bar.empty()\n",
    "        with open(r'twitterdata/{0} {1}.csv'.format(screen_name, oldest), 'w',  encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"id\", \"created_at\", \"text\"])\n",
    "            writer.writerows(outtweets)\n",
    "    except:\n",
    "        print(\"error for {}\".format(screen_name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "\n",
    "PATH_OF_GIT_REPO = r'C:\\Users\\mg\\github\\\\streamlit_tweets_on_charts\\.git'\n",
    "now = datetime.datetime.now()\n",
    "COMMIT_MESSAGE = 'new tweet update {}'.format(now.date())\n",
    "\n",
    "repo = Repo(PATH_OF_GIT_REPO)\n",
    "repo.git.add(\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<git.remote.PushInfo at 0x22629545ef0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.index.commit(COMMIT_MESSAGE)\n",
    "origin = repo.remote(name='origin')\n",
    "origin.push()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43f82cd4cb96a440704902f5d6ad1c0a1208589500b37b572d871d157e2519a1"
  },
  "kernelspec": {
   "display_name": "Python 2.7.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
