{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st#Repo\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.graph_objects as go\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from dateutil import tz\n",
    "import glob\n",
    "import quandl as q\n",
    "import re\n",
    "pd.set_option('display.max_columns', None)\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "# Twitter API credentials\n",
    "consumer_key = os.environ[\"twtr_consumer_key\"]\n",
    "consumer_secret = os.environ[\"twtr_consumer_secret\"]\n",
    "access_key = os.environ[\"twtr_access_key\"]\n",
    "access_secret = os.environ[\"twtr_access_secret\"]\n",
    "quandl_api_key = os.environ[\"quandl_api_key\"]\n",
    "\n",
    "# TODO STORE FILE CREATINO DATE IN CSV FILENAMES TO CHECK WHEN WAS CREATED AND 24 hours limit on updatin new tweets!\n",
    "\n",
    "def get_all_stored_twitter_user_csvs():\n",
    "    # get all csv file names - already scraped users\n",
    "    extension = 'csv'\n",
    "    all_twitter_user_scraped_csvs = glob.glob(\n",
    "        r'twitterdata/*.{}'.format(extension))  # CHANGE FOR SHARE STREAMLIT to /\n",
    "    # filter the price csv\n",
    "    all_twitter_user_scraped_csvs = [\n",
    "        k for k in all_twitter_user_scraped_csvs if 'BITFINEX' not in k]\n",
    "    # filter the price csv\n",
    "    all_twitter_user_scraped_csvs = [\n",
    "        k for k in all_twitter_user_scraped_csvs if 'relevant_words' not in k]\n",
    "\n",
    "    display_name_all_twitter_user_scraped_csvs = [\n",
    "        i.split(' ', 1)[0].split(\"twitterdata\\\\\")[1] for i in all_twitter_user_scraped_csvs]\n",
    "\n",
    "    return display_name_all_twitter_user_scraped_csvs, all_twitter_user_scraped_csvs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_name_all_twitter_user_scraped_csvs, all_twitter_user_scraped_csvs = get_all_stored_twitter_user_csvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['twitterdata\\\\100trillionUSD 1303661563291807745.csv',\n",
       " 'twitterdata\\\\100trillionUSD 1328299487396327427.csv',\n",
       " 'twitterdata\\\\100trillionUSD 1350414544007557120.csv',\n",
       " 'twitterdata\\\\Alice_comfy 1408971288085811200.csv',\n",
       " 'twitterdata\\\\Alice_comfy 1411425879041867776.csv',\n",
       " 'twitterdata\\\\Alice_comfy 1414030084919357443.csv',\n",
       " 'twitterdata\\\\AltcoinGordon 1441359529115992079.csv',\n",
       " 'twitterdata\\\\AltcoinGordon 1489988707683905536.csv',\n",
       " 'twitterdata\\\\APompliano 1417913298549346310.csv',\n",
       " 'twitterdata\\\\APompliano 1457852616906575874.csv',\n",
       " 'twitterdata\\\\BarrySilbert 1054378082059075584.csv',\n",
       " 'twitterdata\\\\BarrySilbert 972094439752519684.csv',\n",
       " 'twitterdata\\\\BillyBobBaghold 1444306376054956031.csv',\n",
       " 'twitterdata\\\\BillyBobBaghold 1474162848297324552.csv',\n",
       " 'twitterdata\\\\BitcoinMagazine 1409942264730816518.csv',\n",
       " 'twitterdata\\\\BitcoinMagazine 1461133227993845765.csv',\n",
       " 'twitterdata\\\\BTCTN 1403132645475815428.csv',\n",
       " 'twitterdata\\\\BTCTN 1459809030063415296.csv',\n",
       " 'twitterdata\\\\coinmamba 1384820550153945087.csv',\n",
       " 'twitterdata\\\\coinmamba 1458350353599041536.csv',\n",
       " 'twitterdata\\\\Cointelegraph 1444948408180121600.csv',\n",
       " 'twitterdata\\\\Cointelegraph 1498673929749250049.csv',\n",
       " 'twitterdata\\\\cryptocobain 1424552429123670018.csv',\n",
       " 'twitterdata\\\\cryptocobain 1425452146636513284.csv',\n",
       " 'twitterdata\\\\CryptoHayes 983996196564987903.csv',\n",
       " 'twitterdata\\\\crypto_birb 1441052327259959295.csv',\n",
       " 'twitterdata\\\\crypto_birb 1483884448366084100.csv',\n",
       " 'twitterdata\\\\crypto_color_ 1420464756662538246.csv',\n",
       " 'twitterdata\\\\cz_binance 1362415022773735430.csv',\n",
       " 'twitterdata\\\\cz_binance 1381075970291949567.csv',\n",
       " 'twitterdata\\\\cz_binance 1451133972864507906.csv',\n",
       " 'twitterdata\\\\cz_binance 1475358494257602561.csv',\n",
       " 'twitterdata\\\\depression2019 1380587805701591042.csv',\n",
       " 'twitterdata\\\\depression2019 1433245334411497473.csv',\n",
       " 'twitterdata\\\\DrGreenApe 943905835666862082.csv',\n",
       " 'twitterdata\\\\ForbesCrypto 1352070198271090687.csv',\n",
       " 'twitterdata\\\\ForbesCrypto 1410236329871478790.csv',\n",
       " 'twitterdata\\\\Grayscale 1186726432719986688.csv',\n",
       " 'twitterdata\\\\Grayscale 1220792641182453760.csv',\n",
       " 'twitterdata\\\\IamNomad 1445091919047053315.csv',\n",
       " 'twitterdata\\\\IamNomad 1495333513788366849.csv',\n",
       " 'twitterdata\\\\inmortalcrypto 1254065589531955199.csv',\n",
       " 'twitterdata\\\\inmortalcrypto 1301905224953716736.csv',\n",
       " 'twitterdata\\\\krakenfx 1331729953939918849.csv',\n",
       " 'twitterdata\\\\krakenfx 1350140338925662208.csv',\n",
       " 'twitterdata\\\\LynAldenContact 1335587636707201025.csv',\n",
       " 'twitterdata\\\\LynAldenContact 1421932400796393481.csv',\n",
       " 'twitterdata\\\\Ninjascalp 1421199283492212735.csv',\n",
       " 'twitterdata\\\\Ninjascalp 1435311148061102083.csv',\n",
       " 'twitterdata\\\\Ninjascalp 1435700614038802432.csv',\n",
       " 'twitterdata\\\\RaoulGMI 1403043795822862342.csv',\n",
       " 'twitterdata\\\\RaoulGMI 1441571672071475200.csv',\n",
       " 'twitterdata\\\\saylor 1455219941901312007.csv',\n",
       " 'twitterdata\\\\saylor 32520560906866687.csv',\n",
       " 'twitterdata\\\\scottmelker 1421923188187992069.csv',\n",
       " 'twitterdata\\\\scottmelker 1478352455331106819.csv',\n",
       " 'twitterdata\\\\siliconebunker 1446764505619390464.csv',\n",
       " 'twitterdata\\\\siliconebunker 1452352880158068744.csv',\n",
       " 'twitterdata\\\\siliconebunker 1455652674494504972.csv',\n",
       " 'twitterdata\\\\TheCryptoDog 1430258286931152907.csv',\n",
       " 'twitterdata\\\\TheCryptoDog 1491638567965106178.csv',\n",
       " 'twitterdata\\\\TheCryptoDog 1491649983975620610.csv',\n",
       " 'twitterdata\\\\ThinkingUSD 1456260876017692676.csv',\n",
       " 'twitterdata\\\\ThinkingUSD 963027493400715264.csv',\n",
       " 'twitterdata\\\\VitalikButerin 1273214816338030600.csv',\n",
       " 'twitterdata\\\\VitalikButerin 1275090572102045697.csv',\n",
       " 'twitterdata\\\\VitalikButerin 1275137891472154623.csv',\n",
       " 'twitterdata\\\\whale_alert 1441982024236126209.csv',\n",
       " 'twitterdata\\\\whale_alert 1478797341251579904.csv',\n",
       " 'twitterdata\\\\wmd4x 1197164740402962431.csv',\n",
       " 'twitterdata\\\\woonomic 1263699211997966336.csv',\n",
       " 'twitterdata\\\\woonomic 1326554174448787455.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_twitter_user_scraped_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100trillionUSD'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_name_user_selection_list_containing_twitter_user = st.sidebar.selectbox(\n",
    "    \"Select existing Twitter-User\", list(display_name_all_twitter_user_scraped_csvs), 0)\n",
    "display_name_user_selection_list_containing_twitter_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map name back to filename:\n",
    "user_selection_list_containing_twitter_user = [\n",
    "    k for k in all_twitter_user_scraped_csvs if display_name_user_selection_list_containing_twitter_user in k]\n",
    "user_selection_list_containing_twitter_user = user_selection_list_containing_twitter_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['twitterdata\\\\100trillionUSD 1303661563291807745.csv',\n",
       " 'twitterdata\\\\100trillionUSD 1328299487396327427.csv',\n",
       " 'twitterdata\\\\100trillionUSD 1350414544007557120.csv']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_selection_list_containing_twitter_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(user_selection_list_containing_twitter_user):\n",
    "display_name_all_twitter_user_scraped_csvs, all_twitter_user_scraped_csvs = get_all_stored_twitter_user_csvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['twitterdata\\\\100trillionUSD 1303661563291807745.csv',\n",
       " 'twitterdata\\\\100trillionUSD 1328299487396327427.csv',\n",
       " 'twitterdata\\\\100trillionUSD 1350414544007557120.csv']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_selection_list_containing_twitter_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st.write(user_selection_list_containing_twitter_user)\n",
    "# st.write(all_twitter_user_scraped_csvs)\n",
    "# map name back to filename:\n",
    "# empty space at the end to check if its the exact same name and\n",
    "# not matching until there like AltcoinGordon for AltcoinGordons\n",
    "# user_selection_list_containing_twitter_user = [\n",
    "#     k for k in all_twitter_user_scraped_csvs if user_selection_list_containing_twitter_user in k]\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['twitterdata\\\\100trillionUSD 1303661563291807745.csv',\n",
       " 'twitterdata\\\\100trillionUSD 1328299487396327427.csv',\n",
       " 'twitterdata\\\\100trillionUSD 1350414544007557120.csv']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_selection_list_containing_twitter_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# here we can get multiple files from different times of scraping the specific user\n",
    "# now we read all of those files and merge them together into one df\n",
    "list_of_dfs = []\n",
    "for user_file in user_selection_list_containing_twitter_user:\n",
    "    tweet_data = pd.read_csv(\"{}\".format(user_file))\n",
    "    list_of_dfs.append(tweet_data)\n",
    "\n",
    "tweet_data = pd.concat(list_of_dfs)\n",
    "\n",
    "st.session_state.first_run = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1456985396815044615</td>\n",
       "      <td>2021-11-06 14:02:42+00:00</td>\n",
       "      <td>RT @WClementeIII: This week I sat down with bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1456900938317418497</td>\n",
       "      <td>2021-11-06 08:27:06+00:00</td>\n",
       "      <td>@Mynima4 ðŸŒ¹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1456900725548666882</td>\n",
       "      <td>2021-11-06 08:26:15+00:00</td>\n",
       "      <td>@fuserleer ðŸŒ¹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1456898176691097602</td>\n",
       "      <td>2021-11-06 08:16:07+00:00</td>\n",
       "      <td>Movie tip for the weekend: V for Vendetta! It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1456763288721649667</td>\n",
       "      <td>2021-11-05 23:20:08+00:00</td>\n",
       "      <td>@geoff_l @Rager I wish that were true, however...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>1350416173490434050</td>\n",
       "      <td>2021-01-16 12:14:39+00:00</td>\n",
       "      <td>@novisport If tether would not be backed (whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>1350415871584460803</td>\n",
       "      <td>2021-01-16 12:13:27+00:00</td>\n",
       "      <td>@Worteltje_Pi @Polylunar_ @nic__carter All tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>1350415328912801795</td>\n",
       "      <td>2021-01-16 12:11:18+00:00</td>\n",
       "      <td>@Polylunar_ @nic__carter Ah ok, didnt see that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>1350414889127448577</td>\n",
       "      <td>2021-01-16 12:09:33+00:00</td>\n",
       "      <td>@melkrever @Geldprinterbrrr Ja dat is wat mijn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>1350414544007557121</td>\n",
       "      <td>2021-01-16 12:08:11+00:00</td>\n",
       "      <td>@Worteltje_Pi @JeeeVeee But BTC is currently (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9663 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                 created_at  \\\n",
       "0     1456985396815044615  2021-11-06 14:02:42+00:00   \n",
       "1     1456900938317418497  2021-11-06 08:27:06+00:00   \n",
       "2     1456900725548666882  2021-11-06 08:26:15+00:00   \n",
       "3     1456898176691097602  2021-11-06 08:16:07+00:00   \n",
       "4     1456763288721649667  2021-11-05 23:20:08+00:00   \n",
       "...                   ...                        ...   \n",
       "3171  1350416173490434050  2021-01-16 12:14:39+00:00   \n",
       "3172  1350415871584460803  2021-01-16 12:13:27+00:00   \n",
       "3173  1350415328912801795  2021-01-16 12:11:18+00:00   \n",
       "3174  1350414889127448577  2021-01-16 12:09:33+00:00   \n",
       "3175  1350414544007557121  2021-01-16 12:08:11+00:00   \n",
       "\n",
       "                                                   text  \n",
       "0     RT @WClementeIII: This week I sat down with bo...  \n",
       "1                                            @Mynima4 ðŸŒ¹  \n",
       "2                                          @fuserleer ðŸŒ¹  \n",
       "3     Movie tip for the weekend: V for Vendetta! It ...  \n",
       "4     @geoff_l @Rager I wish that were true, however...  \n",
       "...                                                 ...  \n",
       "3171  @novisport If tether would not be backed (whic...  \n",
       "3172  @Worteltje_Pi @Polylunar_ @nic__carter All tra...  \n",
       "3173  @Polylunar_ @nic__carter Ah ok, didnt see that...  \n",
       "3174  @melkrever @Geldprinterbrrr Ja dat is wat mijn...  \n",
       "3175  @Worteltje_Pi @JeeeVeee But BTC is currently (...  \n",
       "\n",
       "[9663 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'twitterdata\\\\100trillionUSD 1303661563291807745.csv'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the right naming we take the first entry\n",
    "user_selection_list_containing_twitter_user = user_selection_list_containing_twitter_user[0]\n",
    "user_selection_list_containing_twitter_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "    # streamlit layout\n",
    "    st.title(\"Tweets on charts - {}\".format(\n",
    "        user_selection_list_containing_twitter_user.split(\" \")[0].split(\"twitterdata/\")[1]))\n",
    "\n",
    "    # # # start - read in BTC data # # #\n",
    "    datasource_btcusd = \"BITFINEX/BTCUSD.csv\"\n",
    "    btcusd_data = pd.read_csv(\"coindata/{}\".format(\n",
    "        datasource_btcusd.replace(\"/\", \" \")), index_col=0)\n",
    "    btcusd_data.index = pd.to_datetime(btcusd_data.index)\n",
    "\n",
    "    most_recent_stored_btcusd_date = btcusd_data.sort_index().tail(\n",
    "        1).index[0].strftime(\"%Y-%m-%d\")\n",
    "    todays_date = datetime.date.today() - timedelta(days=1)\n",
    "    todays_date = todays_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # st.write(most_recent_stored_btcusd_date)\n",
    "    # st.write(todays_date)\n",
    "\n",
    "    if most_recent_stored_btcusd_date != todays_date:\n",
    "        data = q.get(datasource_btcusd.split(\".\")[0],   start_date=most_recent_stored_btcusd_date,\n",
    "                     end_date='{}'.format(todays_date),\n",
    "                     api_key=quandl_api_key)\n",
    "        data.info()\n",
    "        data[\"First\"] = data.Last.shift(1)\n",
    "        data.dropna()\n",
    "        btcusd_data = pd.concat([btcusd_data, data])\n",
    "        btcusd_data = btcusd_data.sort_index()\n",
    "        # store current df with up-to-date values\n",
    "        btcusd_data.to_csv('coindata/{}'.format(\n",
    "            datasource_btcusd.replace(\"/\", \" \")), index=True)\n",
    "    # # # end - read in BTC data # # #\n",
    "\n",
    "    # # # start - processing and cleaning of tweets # # #\n",
    "    # Instantiate the sentiment intensity analyzer\n",
    "    rel_tweet_data = tweet_data[tweet_data['text'].str.contains(\n",
    "        '|'.join(option))]\n",
    "    # rel_tweet_data = rel_tweet_data[~rel_tweet_data['text'].str.contains(\"@\")]\n",
    "\n",
    "    rel_tweet_data[\"created_at\"] = pd.to_datetime(\n",
    "        rel_tweet_data[\"created_at\"])\n",
    "    rel_tweet_data['created_at'] = rel_tweet_data['created_at'].dt.tz_localize(\n",
    "        None)\n",
    "    rel_tweet_data['created_at_day'] = rel_tweet_data['created_at'].dt.round(\n",
    "        '1d')\n",
    "    rel_tweet_data_incl_price = pd.merge(\n",
    "        rel_tweet_data, btcusd_data, how=\"left\", left_on=rel_tweet_data[\"created_at_day\"], right_on=btcusd_data.index,)\n",
    "    # # # end - processing and cleaning of tweets # # #\n",
    "\n",
    "    # # # start - chart with tweets # # #\n",
    "    fig = go.Figure(\n",
    "        data=[go.Candlestick(x=btcusd_data.index,\n",
    "                             open=btcusd_data['First'],\n",
    "                             high=btcusd_data['High'],\n",
    "                             low=btcusd_data['Low'],\n",
    "                             close=btcusd_data['Last'],\n",
    "                             name=\"{}\".format(datasource_btcusd.split(\"/\")\n",
    "                                              [1].split(\".\")[0]),\n",
    "                             )],\n",
    "    )\n",
    "\n",
    "    # add tweets to the candle - chart\n",
    "    fig.add_trace(\n",
    "        go.Scatter(mode=\"markers\",\n",
    "                   x=rel_tweet_data_incl_price[\"created_at\"],\n",
    "                   y=rel_tweet_data_incl_price[\"High\"]*1.1,\n",
    "                   name='tweets',\n",
    "                   text=rel_tweet_data_incl_price[\"text\"],\n",
    "                   textposition=\"top center\",\n",
    "                   marker={'color': \"#0d75f8\",  # clear blue\n",
    "                           'size': 4\n",
    "                           }\n",
    "                   )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        # title=\"Plot Title\",\n",
    "        autosize=False,\n",
    "        width=int(1400/1.3),\n",
    "        height=int(800/1.3),\n",
    "        xaxis_range=[rel_tweet_data_incl_price[\"created_at\"].min(\n",
    "        ), rel_tweet_data_incl_price[\"created_at\"].max()]\n",
    "        # fig.layout.xaxis.range[0]:fig.layout.xaxis.range[1]\n",
    "    )\n",
    "    st.plotly_chart(fig)\n",
    "    # # # end - chart with tweets # # #\n",
    "\n",
    "    # # # start - add word cloud # # #\n",
    "    # get all the rows into one string\n",
    "    complete_str = rel_tweet_data['text'].str.cat(sep=' ')\n",
    "\n",
    "    stopwords = set(STOPWORDS)\n",
    "    stopwords.update([\"and\", \"or\", \"https\", \"year\", \"will\", \"post\", \"see\",\n",
    "                      \"going\", \"now\", \"actually\", \"co\", \"go\",  \"look\", \"make\", \"right\", \"people\",\n",
    "                      \"RT\", \"really\", \"first\", \"right\", \"week\", \"still\", \"twitter\",\n",
    "                      \"even\", \"re\", \"lol\", \"new\", \"much\", \"day\", \"haha\", \"dont\", \"well\", \"us\", \"sure\",\n",
    "                      \"don\", \"pretty\", \"looks\", \"Thank\", \"another\", \"thing\", \"view\", \"lot\",\n",
    "                      \"next\", \"many\", \"way\", \"one\", \"Oh\", \"say\", \"im\"])\n",
    "    wordcloud = WordCloud(width=int(1200/1.5), stopwords=stopwords, height=int(800/1.5), max_font_size=200,\n",
    "                          max_words=50, collocations=False, background_color='black').generate(complete_str)\n",
    "    fig = plt.figure(figsize=(40, 30))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    st.pyplot(fig)\n",
    "    # # # end - add word cloud # # #\n",
    "\n",
    "\n",
    "run_it = st.sidebar.button('Show visualizations')\n",
    "\n",
    "st.sidebar.text(\"\")\n",
    "\n",
    "\n",
    "display_name_all_twitter_user_scraped_csvs, all_twitter_user_scraped_csvs = get_all_stored_twitter_user_csvs()\n",
    "\n",
    "display_name_user_selection_list_containing_twitter_user = st.sidebar.selectbox(\n",
    "    \"Select existing Twitter-User\", list(display_name_all_twitter_user_scraped_csvs), 0)\n",
    "\n",
    "# map name back to filename:\n",
    "user_selection_list_containing_twitter_user = [\n",
    "    k for k in all_twitter_user_scraped_csvs if display_name_user_selection_list_containing_twitter_user in k]\n",
    "user_selection_list_containing_twitter_user = user_selection_list_containing_twitter_user[0]\n",
    "\n",
    "allowed_user_input_characters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D',\n",
    "                                 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '$', '%', '_', '!', 'Â§']\n",
    "\n",
    "\n",
    "# add new twitter user data\n",
    "twitter_name = \"\"\n",
    "\n",
    "# update_selected_user = st.sidebar.button(\n",
    "#     'Update tweets')\n",
    "\n",
    "user_input_twitter_name = st.sidebar.text_input(\n",
    "    \"Add new Twitter-User data\", twitter_name)\n",
    "\n",
    "\n",
    "st.sidebar.text(\"\")\n",
    "st.sidebar.text(\"\")\n",
    "\n",
    "new_search_word = \"\"\n",
    "user_input_new_search_word = st.sidebar.text_input(\n",
    "    \"Add new Searchword\", new_search_word)\n",
    "\n",
    "datasource = \"relevant_words.csv\"\n",
    "relevant_words = []\n",
    "with open(\"tmp/\" + datasource, newline='') as inputfile:\n",
    "    for row in csv.reader(inputfile):\n",
    "        relevant_words.append(row)\n",
    "relevant_words = relevant_words[0]\n",
    "\n",
    "if user_input_new_search_word:\n",
    "    button_add_new_searchword = st.sidebar.button('Add Searchword')\n",
    "    if button_add_new_searchword:\n",
    "        if user_input_new_search_word not in relevant_words:\n",
    "\n",
    "            if any(x not in allowed_user_input_characters for x in user_input_new_search_word):\n",
    "                st.error(\n",
    "                    'Character not allowed, please dont use special characters')\n",
    "            else:\n",
    "                relevant_words.append(user_input_new_search_word)\n",
    "                with open(\"tmp/\" + datasource, 'w') as f:\n",
    "                    write = csv.writer(f)\n",
    "                    write.writerow(relevant_words)\n",
    "                st.success('Searchword added')\n",
    "\n",
    "        else:\n",
    "            st.error('Searchword already there')\n",
    "\n",
    "\n",
    "relevant_words = []\n",
    "with open(\"tmp/\" + datasource, newline='') as inputfile:\n",
    "    for row in csv.reader(inputfile):\n",
    "        relevant_words.append(row)\n",
    "relevant_words = relevant_words[0]\n",
    "\n",
    "# # # start - read in BTC data # # #\n",
    "option = st.sidebar.multiselect(\n",
    "    'Searchwords:', relevant_words, relevant_words\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "if run_it or st.session_state.first_run:\n",
    "    main(user_selection_list_containing_twitter_user)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43f82cd4cb96a440704902f5d6ad1c0a1208589500b37b572d871d157e2519a1"
  },
  "kernelspec": {
   "display_name": "Python 2.7.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
